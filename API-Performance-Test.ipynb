{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "The goal is to performance test it. This involves making two requests.\n",
    "\n",
    "The first request is an HTTP GET request to \n",
    "\n",
    "The second request is an HTTP POST request\n",
    "The post body must be JSON and must have two keys: emailId (exactly the same value as you sent before), and uuid (the value that was returned in the previous response). Example:\n",
    "\n",
    "\n",
    "The response if successful will be a HTTP 200\n",
    "You are expected to make each of these requests 100 times and provide the following statistics for the response time of each API:\n",
    "\n",
    "    10th percentile\n",
    "    50th percentile\n",
    "    90th percentile\n",
    "    95th percentile\n",
    "    99th percentile\n",
    "    Mean\n",
    "    Standard Deviation\n",
    "\n",
    "Please note that your solution must be concurrent. That is, you cannot make 200 requests in sequence. You should be making at least 10 requests at a time. Obviously, since one of the requests requires data from the previous response, you will have to do those in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, requests\n",
    "import numpy as np\n",
    "import gevent\n",
    "\n",
    "def get_api_execution_time(emailID):\n",
    "    \"\"\"\n",
    "    To performance test of get and post api\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #Call get API\n",
    "        url = \"http://surya-interview.appspot.com/message\"\n",
    "        getAPIData = {'X-Surya-Email-Id':emailID}\n",
    "        getAPIResponse = requests.get(url,headers=getAPIData)\n",
    "        getAPIExecutionTime = getAPIResponse.elapsed.total_seconds()\n",
    "        #Call post API\n",
    "        postAPIData = json.dumps(getAPIResponse.json())\n",
    "        postAPIHeaders = {\"Content-Type\": \"application/json\"}\n",
    "        postAPIResponse = requests.post(url, data=postAPIData,headers=postAPIHeaders)   \n",
    "        postAPIResponseTime = postAPIResponse.elapsed.total_seconds()\n",
    "    except:\n",
    "        getAPIExecutionTime = 0\n",
    "        postAPIResponseTime = 0\n",
    "    return getAPIExecutionTime,postAPIResponseTime\n",
    "\n",
    "def get_mean_value(listOfValue):\n",
    "    \"\"\"\n",
    "    To get mean value \n",
    "    \"\"\"\n",
    "    listNumpy = np.array(listOfValue)\n",
    "    meanValue = np.mean(listNumpy)\n",
    "    return meanValue\n",
    "\n",
    "def get_standard_deviation(listOfValue):\n",
    "    \"\"\"\n",
    "    To get standard deviation value\n",
    "    \"\"\"\n",
    "    listNumpy = np.array(listOfValue)\n",
    "    stdValue = np.std(listNumpy)\n",
    "    return stdValue\n",
    "\n",
    "getAPIExecutionTimeList = []\n",
    "postAPIExecutionTimeList = []  \n",
    "def get_api_performance_statistics(totalNoRequest,batchSize,currentBatch,batchCount):\n",
    "    \"\"\"\n",
    "    To get API performance statistics\n",
    "    \"\"\"\n",
    "    print \"Current batch no is : %s\" %(currentBatch)\n",
    "    for i in range(1,batchSize+1):\n",
    "        EmailID = \"gps@surya-soft.com\" #we can pass configurable email id\n",
    "        getTime,postTime = get_api_execution_time(EmailID)\n",
    "        getAPIExecutionTimeList.append(getTime)\n",
    "        postAPIExecutionTimeList.append(postTime)\n",
    "        \n",
    "    #After complete all batch use Execution time list array for calculate time statistics\n",
    "    if currentBatch == batchCount: \n",
    "        #10th percentile\n",
    "        percentile_10 = int(round(0.10*totalNoRequest))\n",
    "        print \"percentile_10\",percentile_10\n",
    "        #Python list index start from 0 i,e I did percentile_10-1 to get percentile_10 element \n",
    "        print \"Get API 10th percentile Time  : %s\" %(getAPIExecutionTimeList[percentile_10-1]) \n",
    "        print \"POST API 10th percentile Time : %s\" %(postAPIExecutionTimeList[percentile_10-1])\n",
    "        #50th percentile\n",
    "        percentile_50= int(round(0.50*totalNoRequest))\n",
    "        print \"percentile_50\",percentile_50\n",
    "        print \"Get API 50th percentile Time  : %s\" %(getAPIExecutionTimeList[percentile_50-1])\n",
    "        print \"POST API 50th percentile Time : %s\" %(postAPIExecutionTimeList[percentile_50-1])\n",
    "\n",
    "        #90th percentile\n",
    "        percentile_90 = int(round(0.90*totalNoRequest))\n",
    "        print \"Get API 90th percentile Time  : %s\" %(getAPIExecutionTimeList[percentile_90-1])\n",
    "        print \"POST API 90th percentile Time : %s\" %(postAPIExecutionTimeList[percentile_90-1])\n",
    "        #95th percentile\n",
    "        percentile_95 = int(round(0.95*totalNoRequest))\n",
    "        print \"Get API 95th percentile Time  : %s\" %(getAPIExecutionTimeList[percentile_95-1])\n",
    "        print \"POST API 95th percentile Time : %s\" %(postAPIExecutionTimeList[percentile_95-1])\n",
    "        #99th percentile\n",
    "        percentile_99 = int(round(0.99*totalNoRequest))\n",
    "        print \"Get API 99th percentile Time  : %s\" %(getAPIExecutionTimeList[percentile_99-1])\n",
    "        print \"POST API 99th percentile Time : %s\" %(postAPIExecutionTimeList[percentile_99-1])\n",
    "        #Mean\n",
    "        getMean = get_mean_value(getAPIExecutionTimeList)\n",
    "        postMean = get_mean_value(postAPIExecutionTimeList)\n",
    "        print \"Get API MEAN Time %s\" %(getMean)\n",
    "        print \"Post API MEAN Time %s\" %(postMean)\n",
    "        #Standard Deviation\n",
    "        getDeviation = get_standard_deviation(getAPIExecutionTimeList)\n",
    "        postDeviation = get_standard_deviation(postAPIExecutionTimeList)\n",
    "        print \"Get API Standard Deviation Time %s\" %(getDeviation)\n",
    "        print \"Post API Standard Deviation Time %s\" %(postDeviation)\n",
    "\n",
    "        print \"getAPIExecutionTimeList\",getAPIExecutionTimeList\n",
    "        print \"postAPIExecutionTimeList\",postAPIExecutionTimeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def asynchronous(totalNoRequest=10,batchSize = 1):\n",
    "    \"\"\"\n",
    "    Use gevent module for python asynchronous call\n",
    "    \"\"\"\n",
    "    batchCount = int(totalNoRequest/batchSize)\n",
    "    if batchCount ==0:\n",
    "        batchCount=1\n",
    "        batchSize = totalNoRequest\n",
    "    threads = [gevent.spawn(get_api_performance_statistics, totalNoRequest,batchSize,currentBatch,batchCount) for currentBatch in range(1,batchCount+1)]\n",
    "    print \"Threads \",threads\n",
    "    gevent.joinall(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads  [<Greenlet at 0x7fcd6da14f50: get_api_performance_statistics(100, 10, 1, 10)>, <Greenlet at 0x7fcd6da14370: get_api_performance_statistics(100, 10, 2, 10)>, <Greenlet at 0x7fcd6da14e10: get_api_performance_statistics(100, 10, 3, 10)>, <Greenlet at 0x7fcd6da14550: get_api_performance_statistics(100, 10, 4, 10)>, <Greenlet at 0x7fcd6da14730: get_api_performance_statistics(100, 10, 5, 10)>, <Greenlet at 0x7fcd6da14c30: get_api_performance_statistics(100, 10, 6, 10)>, <Greenlet at 0x7fcd6da14410: get_api_performance_statistics(100, 10, 7, 10)>, <Greenlet at 0x7fcd6da14eb0: get_api_performance_statistics(100, 10, 8, 10)>, <Greenlet at 0x7fcd885dd050: get_api_performance_statistics(100, 10, 9, 10)>, <Greenlet at 0x7fcd885dd0f0: get_api_performance_statistics(100, 10, 10, 10)>]\n",
      "Current batch no is : 1\n",
      "Current batch no is : 2\n",
      "Current batch no is : 3\n",
      "Current batch no is : 4\n",
      "Current batch no is : 5\n",
      "Current batch no is : 6\n",
      "Current batch no is : 7\n",
      "Current batch no is : 8\n",
      "Current batch no is : 9\n",
      "Current batch no is : 10\n",
      "percentile_10 10\n",
      "Get API 10th percentile Time  : 0.420093\n",
      "POST API 10th percentile Time : 0.400002\n",
      "percentile_50 50\n",
      "Get API 50th percentile Time  : 0.55998\n",
      "POST API 50th percentile Time : 0.63641\n",
      "Get API 90th percentile Time  : 0.644225\n",
      "POST API 90th percentile Time : 0.628775\n",
      "Get API 95th percentile Time  : 0.526948\n",
      "POST API 95th percentile Time : 0.635641\n",
      "Get API 99th percentile Time  : 0.404191\n",
      "POST API 99th percentile Time : 0.412623\n",
      "Get API MEAN Time 0.8946745\n",
      "Post API MEAN Time 0.59694803\n",
      "Get API Standard Deviation Time 3.0757807866\n",
      "Post API Standard Deviation Time 0.121666689985\n",
      "getAPIExecutionTimeList [0.475052, 0.637594, 0.402523, 0.635586, 0.423352, 0.641087, 0.639515, 0.639426, 0.639153, 0.420093, 0.767726, 0.549584, 0.637352, 0.635453, 0.634672, 0.421249, 0.424954, 0.832926, 0.535327, 0.550301, 0.528933, 0.482011, 0.635373, 0.636146, 0.635752, 0.423757, 0.422623, 0.635518, 0.636163, 0.397421, 0.691701, 0.637649, 0.66933, 0.605537, 0.786904, 0.637883, 0.628312, 0.533669, 0.425722, 0.636533, 0.636044, 0.637196, 0.638405, 0.639691, 0.637779, 0.638471, 0.7093, 0.637892, 0.639041, 0.55998, 0.635624, 0.636145, 0.635409, 0.636809, 0.637524, 0.635511, 0.638073, 0.635569, 0.710419, 0.632907, 0.56281, 0.637546, 0.636553, 0.398704, 0.637526, 0.638349, 0.637691, 0.639041, 0.636895, 0.638577, 0.636121, 0.637566, 0.405434, 0.397976, 0.638498, 0.630533, 0.633136, 0.637466, 0.530508, 0.423698, 0, 31.478107, 0.635177, 0.638036, 0.638555, 0.630661, 0.638064, 0.40367, 0.640258, 0.644225, 0.407422, 0.452057, 0.63987, 0.637125, 0.526948, 0.641355, 0.650709, 0.636985, 0.404191, 0.451756]\n",
      "postAPIExecutionTimeList [0.486559, 0.577876, 0.60668, 0.635313, 0.528187, 0.634314, 0.634298, 0.634632, 0.63549, 0.400002, 0.406178, 0.63975, 0.636113, 0.63837, 0.63724, 0.476782, 0.706431, 0.421922, 0.401986, 0.422942, 0.472866, 0.635739, 0.638115, 0.637142, 0.635455, 0.530682, 0.533372, 0.636678, 0.5635, 0.575592, 0.635522, 0.636243, 0.637831, 0.4852, 0.637713, 0.64453, 0.420677, 0.632219, 0.530082, 0.636126, 0.635445, 0.636013, 0.636102, 0.632355, 0.635661, 0.56227, 0.636684, 0.633523, 1.355727, 0.63641, 0.636074, 0.639598, 0.635175, 0.636857, 0.636564, 0.634687, 0.636859, 0.566115, 0.639466, 0.637323, 0.706396, 0.635868, 0.635837, 0.554223, 0.636537, 0.634077, 0.634146, 0.635455, 0.635736, 0.636706, 0.63457, 0.635019, 0.545811, 0.557932, 0.643028, 0.637812, 0.635473, 0.424209, 0.637657, 0.53066, 0, 0.571276, 0.638261, 0.637247, 0.642365, 0.633686, 0.634623, 0.549515, 0.633948, 0.628775, 0.410223, 0.635193, 0.635572, 0.425157, 0.635641, 0.618453, 0.635853, 0.637829, 0.412623, 0.636154]\n"
     ]
    }
   ],
   "source": [
    "#we can configure total no of request and batchsize like 100 and 10\n",
    "asynchronous(100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
